{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15661f9f",
   "metadata": {},
   "source": [
    "# Synaptipy — Batch Analysis Example\n",
    "\n",
    "This notebook demonstrates how to use Synaptipy’s core analysis engine\n",
    "programmatically — without opening the GUI — to:\n",
    "\n",
    "1. Load electrophysiology files from disk (ABF format)\n",
    "2. Run spike detection and input-resistance analysis\n",
    "3. Collect results into a Pandas DataFrame\n",
    "4. Plot summary statistics\n",
    "\n",
    "**Requirements:** `pip install synaptipy matplotlib pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Synaptipy core imports\n",
    "from Synaptipy.infrastructure.file_readers.neo_adapter import NeoAdapter\n",
    "from Synaptipy.core.analysis.spike_analysis import detect_spikes_threshold\n",
    "from Synaptipy.core.analysis.intrinsic_properties import calculate_rin\n",
    "from Synaptipy.core.analysis.basic_features import calculate_rmp\n",
    "\n",
    "print(\"Synaptipy imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1043cf",
   "metadata": {},
   "source": [
    "## 1. Discover Data Files\n",
    "\n",
    "Point to the `examples/data/` folder that ships with the repository.\n",
    "These are Axon ABF recordings from whole-cell patch-clamp experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "abf_files = sorted(data_dir.glob(\"*.abf\"))\n",
    "print(f\"Found {len(abf_files)} ABF files:\")\n",
    "for f in abf_files:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f754d",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect a Single Recording\n",
    "\n",
    "Use `NeoAdapter` to read the file into Synaptipy’s `Recording` data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = NeoAdapter()\n",
    "recording = adapter.read_recording(abf_files[0])\n",
    "\n",
    "print(f\"File: {abf_files[0].name}\")\n",
    "print(f\"Sampling rate: {recording.sampling_rate} Hz\")\n",
    "print(f\"Channels: {len(recording.channels)}\")\n",
    "for ch_id, ch in recording.channels.items():\n",
    "    n_trials = len(ch.data_trials) if ch.data_trials else 0\n",
    "    print(f\"  [{ch_id}] {ch.name} ({ch.units}) — {n_trials} trial(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b89bf6",
   "metadata": {},
   "source": [
    "## 3. Analyse a Single Trace\n",
    "\n",
    "Extract the first voltage channel and run RMP + spike detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first voltage channel\n",
    "v_channel = None\n",
    "for ch in recording.channels.values():\n",
    "    if ch.units and ch.units.lower() in (\"mv\", \"v\"):\n",
    "        v_channel = ch\n",
    "        break\n",
    "\n",
    "if v_channel is None:\n",
    "    print(\"No voltage channel found — using first channel.\")\n",
    "    v_channel = list(recording.channels.values())[0]\n",
    "\n",
    "data = v_channel.data_trials[0]  # first trial\n",
    "fs = v_channel.sampling_rate or recording.sampling_rate\n",
    "dt = 1.0 / fs\n",
    "time = np.arange(len(data)) * dt + float(getattr(v_channel, 't_start', 0.0))\n",
    "\n",
    "print(f\"Channel: {v_channel.name}, {len(data)} samples, {fs} Hz\")\n",
    "print(f\"Duration: {time[-1] - time[0]:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw trace\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "ax.plot(time, data, linewidth=0.5)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(f\"Voltage ({v_channel.units})\")\n",
    "ax.set_title(f\"{abf_files[0].name} — Trial 1\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike detection\n",
    "refractory_samples = int(0.002 * fs)  # 2 ms refractory period\n",
    "spike_result = detect_spikes_threshold(\n",
    "    data, time,\n",
    "    threshold=-20.0,\n",
    "    refractory_samples=refractory_samples,\n",
    ")\n",
    "\n",
    "n_spikes = len(spike_result.spike_times) if spike_result.spike_times is not None else 0\n",
    "print(f\"Spikes detected: {n_spikes}\")\n",
    "if n_spikes > 0:\n",
    "    print(f\"Mean frequency: {spike_result.mean_frequency:.1f} Hz\")\n",
    "    print(f\"Spike times (first 5): {spike_result.spike_times[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec683daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMP analysis\n",
    "rmp_result = calculate_rmp(\n",
    "    data, time,\n",
    "    baseline_window=(time[0], time[0] + 0.1),\n",
    ")\n",
    "print(f\"RMP: {rmp_result.value:.2f} {rmp_result.unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a11b6",
   "metadata": {},
   "source": [
    "## 4. Batch Processing Across All Files\n",
    "\n",
    "Loop over every ABF file, run spike detection, and collect results\n",
    "into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c923a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for fpath in abf_files:\n",
    "    try:\n",
    "        rec = adapter.read_recording(fpath)\n",
    "    except Exception as e:\n",
    "        print(f\"  Skipping {fpath.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Find voltage channel\n",
    "    v_ch = None\n",
    "    for ch in rec.channels.values():\n",
    "        if ch.units and ch.units.lower() in (\"mv\", \"v\"):\n",
    "            v_ch = ch\n",
    "            break\n",
    "    if v_ch is None:\n",
    "        v_ch = list(rec.channels.values())[0]\n",
    "\n",
    "    fs_file = v_ch.sampling_rate or rec.sampling_rate\n",
    "    refractory = int(0.002 * fs_file)\n",
    "\n",
    "    for trial_idx, trial_data in enumerate(v_ch.data_trials):\n",
    "        t = np.arange(len(trial_data)) / fs_file\n",
    "        sr = detect_spikes_threshold(\n",
    "            trial_data, t,\n",
    "            threshold=-20.0,\n",
    "            refractory_samples=refractory,\n",
    "        )\n",
    "        n_sp = len(sr.spike_times) if sr.spike_times is not None else 0\n",
    "        rows.append({\n",
    "            \"file\": fpath.name,\n",
    "            \"channel\": v_ch.name,\n",
    "            \"trial\": trial_idx,\n",
    "            \"spike_count\": n_sp,\n",
    "            \"mean_freq_hz\": sr.mean_frequency if n_sp > 0 else 0.0,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Processed {len(abf_files)} files, {len(df)} total sweeps.\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfeb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics per file\n",
    "summary = df.groupby(\"file\").agg(\n",
    "    total_spikes=(\"spike_count\", \"sum\"),\n",
    "    mean_freq=(\"mean_freq_hz\", \"mean\"),\n",
    "    n_trials=(\"trial\", \"count\"),\n",
    ").reset_index()\n",
    "\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of spike counts per file\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.bar(summary[\"file\"], summary[\"total_spikes\"])\n",
    "ax.set_ylabel(\"Total Spike Count\")\n",
    "ax.set_xlabel(\"File\")\n",
    "ax.set_title(\"Spike Counts Across Recordings\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e0f4a",
   "metadata": {},
   "source": [
    "## 5. Export Results to CSV\n",
    "\n",
    "Save the full results DataFrame for downstream analysis in R, MATLAB, or\n",
    "any other statistics package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71af69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = Path(\"batch_spike_results.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Results saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
